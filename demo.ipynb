{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.ticker as mticker\n",
    "import regex as re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 3.94 GiB of which 60.00 MiB is free. Process 5468 has 1.39 GiB memory in use. Including non-PyTorch memory, this process has 1.99 GiB memory in use. Of the allocated memory 1.92 GiB is allocated by PyTorch, and 27.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 21\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mframefinder\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m framelabels\n\u001b[1;32m      3\u001b[0m candidate_labels \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEconomic: costs, benefits, or other financial implications\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m      5\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCapacity and resources: availability of physical, human or financial resources, and capacity of current systems\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOther: any coherent group of frames not covered by the above categories\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     19\u001b[0m ]\n\u001b[0;32m---> 21\u001b[0m framing_labels \u001b[38;5;241m=\u001b[39m \u001b[43mframelabels\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mFramingLabels\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mfacebook/bart-large-mnli\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcandidate_labels\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/framefinder/framelabels.py:19\u001b[0m, in \u001b[0;36mFramingLabels.__init__\u001b[0;34m(self, base_model, candidate_labels, batch_size)\u001b[0m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, base_model, candidate_labels, batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m):\n\u001b[1;32m     18\u001b[0m     device \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcuda:0\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcuda\u001b[38;5;241m.\u001b[39mis_available() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m---> 19\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_pipeline \u001b[38;5;241m=\u001b[39m \u001b[43mpipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mzero-shot-classification\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbase_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcandidate_labels \u001b[38;5;241m=\u001b[39m candidate_labels\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassifier \u001b[38;5;241m=\u001b[39m partial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbase_pipeline, candidate_labels\u001b[38;5;241m=\u001b[39mcandidate_labels, multi_label\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, batch_size\u001b[38;5;241m=\u001b[39mbatch_size)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/pipelines/__init__.py:1107\u001b[0m, in \u001b[0;36mpipeline\u001b[0;34m(task, model, config, tokenizer, feature_extractor, image_processor, framework, revision, use_fast, token, device, device_map, torch_dtype, trust_remote_code, model_kwargs, pipeline_class, **kwargs)\u001b[0m\n\u001b[1;32m   1104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m device \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1105\u001b[0m     kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdevice\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m device\n\u001b[0;32m-> 1107\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpipeline_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mframework\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mframework\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/pipelines/zero_shot_classification.py:89\u001b[0m, in \u001b[0;36mZeroShotClassificationPipeline.__init__\u001b[0;34m(self, args_parser, *args, **kwargs)\u001b[0m\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\u001b[38;5;28mself\u001b[39m, args_parser\u001b[38;5;241m=\u001b[39mZeroShotClassificationArgumentHandler(), \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m     88\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_args_parser \u001b[38;5;241m=\u001b[39m args_parser\n\u001b[0;32m---> 89\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mentailment_id \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m     91\u001b[0m         logger\u001b[38;5;241m.\u001b[39mwarning(\n\u001b[1;32m     92\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to determine \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mentailment\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m label id from the label2id mapping in the model config. Setting to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     93\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-1. Define a descriptive label2id mapping in the model config to ensure correct outputs.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     94\u001b[0m         )\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/pipelines/base.py:874\u001b[0m, in \u001b[0;36mPipeline.__init__\u001b[0;34m(self, model, tokenizer, feature_extractor, image_processor, modelcard, framework, task, args_parser, device, torch_dtype, binary_output, **kwargs)\u001b[0m\n\u001b[1;32m    867\u001b[0m \u001b[38;5;66;03m# We shouldn't call `model.to()` for models loaded with accelerate\u001b[39;00m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mframework \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice, \u001b[38;5;28mint\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m    872\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m hf_device_map \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    873\u001b[0m ):\n\u001b[0;32m--> 874\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[38;5;66;03m# Update config and generation_config with task specific parameters\u001b[39;00m\n\u001b[1;32m    877\u001b[0m task_specific_params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mtask_specific_params\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/modeling_utils.py:2556\u001b[0m, in \u001b[0;36mPreTrainedModel.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2551\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dtype_present_in_args:\n\u001b[1;32m   2552\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   2553\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou cannot cast a GPTQ model in a new `dtype`. Make sure to load the model using `from_pretrained` using the desired\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2554\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m `dtype` by passing the correct `torch_dtype` argument.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   2555\u001b[0m         )\n\u001b[0;32m-> 2556\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1152\u001b[0m, in \u001b[0;36mModule.to\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1148\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1149\u001b[0m                     non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[1;32m   1150\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m, non_blocking)\n\u001b[0;32m-> 1152\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:802\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 802\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    806\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    807\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:802\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 802\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    806\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    807\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "    \u001b[0;31m[... skipping similar frames: Module._apply at line 802 (2 times)]\u001b[0m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:802\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    800\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m recurse:\n\u001b[1;32m    801\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 802\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    804\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    805\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    806\u001b[0m         \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    807\u001b[0m         \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    812\u001b[0m         \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    813\u001b[0m         \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:825\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn, recurse)\u001b[0m\n\u001b[1;32m    821\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    822\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    823\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    824\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 825\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    826\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    827\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1150\u001b[0m, in \u001b[0;36mModule.to.<locals>.convert\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m   1147\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m convert_to_format \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m t\u001b[38;5;241m.\u001b[39mdim() \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;241m4\u001b[39m, \u001b[38;5;241m5\u001b[39m):\n\u001b[1;32m   1148\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m t\u001b[38;5;241m.\u001b[39mto(device, dtype \u001b[38;5;28;01mif\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_floating_point() \u001b[38;5;129;01mor\u001b[39;00m t\u001b[38;5;241m.\u001b[39mis_complex() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   1149\u001b[0m                 non_blocking, memory_format\u001b[38;5;241m=\u001b[39mconvert_to_format)\n\u001b[0;32m-> 1150\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdtype\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_floating_point\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mis_complex\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 16.00 MiB. GPU 0 has a total capacity of 3.94 GiB of which 60.00 MiB is free. Process 5468 has 1.39 GiB memory in use. Including non-PyTorch memory, this process has 1.99 GiB memory in use. Of the allocated memory 1.92 GiB is allocated by PyTorch, and 27.52 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "from framefinder import framelabels\n",
    "\n",
    "candidate_labels = [\n",
    "    \"Economic: costs, benefits, or other financial implications\",\n",
    "    \"Capacity and resources: availability of physical, human or financial resources, and capacity of current systems\",\n",
    "    \"Morality: religious or ethical implications\",\n",
    "    \"Fairness and equality: balance or distribution of rights, responsibilities, and resources\",\n",
    "    \"Legality, constitutionality and jurisprudence: rights, freedoms, and authority of individuals, corporations, and government\",\n",
    "    \"Policy prescription and evaluation: discussion of specific policies aimed at addressing problems\",\n",
    "    \"Crime and punishment: effectiveness and implications of laws and their enforcement\",\n",
    "    \"Security and defense: threats to welfare of the individual, community, or nation\",\n",
    "    \"Health and safety: health care, sanitation, public safety\",\n",
    "    \"Quality of life: threats and opportunities for the individual’s wealth, happiness, and well-being\",\n",
    "    \"Cultural identity: traditions, customs, or values of a social group in relation to a policy issue\",\n",
    "    \"Public opinion: attitudes and opinions of the general public, including polling and demographics\",\n",
    "    \"Political: considerations related to politics and politicians, including lobbying, elections, and attempts to sway voters\",\n",
    "    \"External regulation and reputation: international reputation or foreign policy of the U.S.\",\n",
    "    \"Other: any coherent group of frames not covered by the above categories\",\n",
    "]\n",
    "\n",
    "framing_labels = framelabels.FramingLabels(\"facebook/bart-large-mnli\", candidate_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from framefinder import framedimensions\n",
    "\n",
    "dimensions = [\n",
    "    \"Care: ...acted with kindness, compassion, or empathy, or nurtured another person.\",\n",
    "    \"Harm: ...acted with cruelty, or hurt or harmed another person/animal and caused suffering.\",\n",
    "    \"Fairness: ...acted in a fair manner, promoting equality, justice, or rights.\",\n",
    "    \"Cheating: ...was unfair or cheated, or caused an injustice or engaged in fraud.\",\n",
    "    \"Loyalty: ...acted with fidelity, or as a team player, or was loyal or patriotic.\",\n",
    "    \"Betrayal: ...acted disloyal, betrayed someone, was disloyal, or was a traitor.\",\n",
    "    \"Authority: ...obeyed, or acted with respect for authority or tradition.\",\n",
    "    \"Subversion: ...disobeyed or showed disrespect, or engaged in subversion or caused chaos.\",\n",
    "    \"Sanctity: ...acted in a way that was wholesome or sacred, or displayed purity or sanctity.\",\n",
    "    \"Degredation: ...was depraved, degrading, impure, or unnatural.\",\n",
    "]\n",
    "pole_names = [\n",
    "    (\"Care\", \"Harm\"),\n",
    "    (\"Fairness\", \"Cheating\"),\n",
    "    (\"Loyalty\", \"Betrayal\"),\n",
    "    (\"Authority\", \"Subversion\"),\n",
    "    (\"Sanctity\", \"Degredation\"),\n",
    "]\n",
    "base_model = 'all-mpnet-base-v2'\n",
    "framing_dimensions = framedimensions.FramingDimensions(base_model, dimensions, pole_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def read_files(filenames):\n",
    "    files = []\n",
    "    for file_name in filenames:\n",
    "        with open(\"articles/\" + file_name, 'r',encoding=\"utf8\") as file:\n",
    "            files.append(file.read())\n",
    "    return files\n",
    "\n",
    "def clean_string(text):\n",
    "    text = text.replace(\"[\", \"\").replace(\"]\", \"\")\n",
    "    text = re.sub('\\{\\{.*}}', '', text)\n",
    "    text = text.split(\"== See also ==\")[0]\n",
    "    return text\n",
    "\n",
    "def extract_source(text):\n",
    "    text = text.split('You can view and copy the source of this page:</div><textarea readonly=\"\" accesskey=\",\" id=\"wpTextbox1\" cols=\"80\" rows=\"25\" style=\"\" class=\"mw-editfont-monospace\" lang=\"en\" dir=\"ltr\" name=\"wpTextbox1\">')[1]\n",
    "    return text.split('</textarea><')[0]\n",
    "    \n",
    "def fetch_wiki_articles(articles): # ? might not work for all articles, need to test\n",
    "    article_texts = []\n",
    "    for article in articles:\n",
    "        response = requests.get(f\"https://en.wikipedia.org/w/index.php?title={article}&action=edit\")\n",
    "        text = extract_source(response.text)\n",
    "        article_texts.append(clean_string(text))\n",
    "    return article_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch articles directly from wikipedia\n",
    "article_titles = [\"Anti-abortion_movements\", \"Abortion-rights_movements\"]\n",
    "articles = fetch_wiki_articles(article_titles)\n",
    "\n",
    "# local files\n",
    "# articles = read_files(article_titles)\n",
    "# articles = [clean_string(article) for article in articles]\n",
    "\n",
    "#print(articles[0])\n",
    "# todo article cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 3.94 GiB of which 38.75 MiB is free. Process 5468 has 1.39 GiB memory in use. Including non-PyTorch memory, this process has 2.11 GiB memory in use. Of the allocated memory 2.00 GiB is allocated by PyTorch, and 52.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m labels \u001b[38;5;241m=\u001b[39m \u001b[43mframing_labels\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtexts\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m labels_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame(labels)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mticker\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mmticker\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/framefinder/framelabels.py:47\u001b[0m, in \u001b[0;36mFramingLabels.__call__\u001b[0;34m(self, sequence_to_classify)\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, sequence_to_classify):\n\u001b[0;32m---> 47\u001b[0m     scores \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_ordered_scores\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequence_to_classify\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     48\u001b[0m     label_names \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_label_names()\n\u001b[1;32m     49\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mdict\u001b[39m(\u001b[38;5;28mzip\u001b[39m(label_names, scores))\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/framefinder/framelabels.py:31\u001b[0m, in \u001b[0;36mFramingLabels.get_ordered_scores\u001b[0;34m(self, sequence_to_classify)\u001b[0m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mtype\u001b[39m(sequence_to_classify) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlist\u001b[39m:\n\u001b[1;32m     30\u001b[0m     res \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m---> 31\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m out \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtqdm(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mclassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43msequence_to_classify\u001b[49m\u001b[43m)\u001b[49m):\n\u001b[1;32m     32\u001b[0m         res\u001b[38;5;241m.\u001b[39mappend(out)\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/pipelines/zero_shot_classification.py:206\u001b[0m, in \u001b[0;36mZeroShotClassificationPipeline.__call__\u001b[0;34m(self, sequences, *args, **kwargs)\u001b[0m\n\u001b[1;32m    203\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    204\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to understand extra arguments \u001b[39m\u001b[38;5;132;01m{\u001b[39;00margs\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 206\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43msequences\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/pipelines/base.py:1177\u001b[0m, in \u001b[0;36mPipeline.__call__\u001b[0;34m(self, inputs, num_workers, batch_size, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1173\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m can_use_iterator:\n\u001b[1;32m   1174\u001b[0m     final_iterator \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_iterator(\n\u001b[1;32m   1175\u001b[0m         inputs, num_workers, batch_size, preprocess_params, forward_params, postprocess_params\n\u001b[1;32m   1176\u001b[0m     )\n\u001b[0;32m-> 1177\u001b[0m     outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfinal_iterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1178\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m outputs\n\u001b[1;32m   1179\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/pipelines/pt_utils.py:124\u001b[0m, in \u001b[0;36mPipelineIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_item()\n\u001b[1;32m    123\u001b[0m \u001b[38;5;66;03m# We're out of items within a batch\u001b[39;00m\n\u001b[0;32m--> 124\u001b[0m item \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    125\u001b[0m processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfer(item, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparams)\n\u001b[1;32m    126\u001b[0m \u001b[38;5;66;03m# We now have a batch of \"inferred things\".\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/pipelines/pt_utils.py:266\u001b[0m, in \u001b[0;36mPipelinePackIterator.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    263\u001b[0m             \u001b[38;5;28;01mreturn\u001b[39;00m accumulator\n\u001b[1;32m    265\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_last:\n\u001b[0;32m--> 266\u001b[0m     processed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minfer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43miterator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mparams\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    267\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mloader_batch_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    268\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(processed, torch\u001b[38;5;241m.\u001b[39mTensor):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/pipelines/base.py:1102\u001b[0m, in \u001b[0;36mPipeline.forward\u001b[0;34m(self, model_inputs, **forward_params)\u001b[0m\n\u001b[1;32m   1100\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m inference_context():\n\u001b[1;32m   1101\u001b[0m         model_inputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_inputs, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice)\n\u001b[0;32m-> 1102\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mforward_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1103\u001b[0m         model_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_ensure_tensor_on_device(model_outputs, device\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mdevice(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcpu\u001b[39m\u001b[38;5;124m\"\u001b[39m))\n\u001b[1;32m   1104\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/pipelines/zero_shot_classification.py:229\u001b[0m, in \u001b[0;36mZeroShotClassificationPipeline._forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m    227\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(model_forward)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m    228\u001b[0m     model_inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124muse_cache\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m--> 229\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_inputs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    231\u001b[0m model_outputs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    232\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcandidate_label\u001b[39m\u001b[38;5;124m\"\u001b[39m: candidate_label,\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msequence\u001b[39m\u001b[38;5;124m\"\u001b[39m: sequence,\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_last\u001b[39m\u001b[38;5;124m\"\u001b[39m: inputs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mis_last\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m    235\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moutputs,\n\u001b[1;32m    236\u001b[0m }\n\u001b[1;32m    237\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model_outputs\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py:1891\u001b[0m, in \u001b[0;36mBartForSequenceClassification.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, inputs_embeds, decoder_inputs_embeds, labels, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1886\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m input_ids \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1887\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mNotImplementedError\u001b[39;00m(\n\u001b[1;32m   1888\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing input embeddings is currently not supported for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1889\u001b[0m     )\n\u001b[0;32m-> 1891\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1892\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1893\u001b[0m \u001b[43m    \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1894\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_input_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1895\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_attention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1896\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1897\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1898\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcross_attn_head_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1899\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoder_outputs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoder_outputs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1900\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1901\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdecoder_inputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1902\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_cache\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_cache\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1903\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1904\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1905\u001b[0m \u001b[43m    \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1906\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1907\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m outputs[\u001b[38;5;241m0\u001b[39m]  \u001b[38;5;66;03m# last hidden state\u001b[39;00m\n\u001b[1;32m   1909\u001b[0m eos_mask \u001b[38;5;241m=\u001b[39m input_ids\u001b[38;5;241m.\u001b[39meq(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39meos_token_id)\u001b[38;5;241m.\u001b[39mto(hidden_states\u001b[38;5;241m.\u001b[39mdevice)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py:1599\u001b[0m, in \u001b[0;36mBartModel.forward\u001b[0;34m(self, input_ids, attention_mask, decoder_input_ids, decoder_attention_mask, head_mask, decoder_head_mask, cross_attn_head_mask, encoder_outputs, past_key_values, inputs_embeds, decoder_inputs_embeds, use_cache, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1596\u001b[0m return_dict \u001b[38;5;241m=\u001b[39m return_dict \u001b[38;5;28;01mif\u001b[39;00m return_dict \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39muse_return_dict\n\u001b[1;32m   1598\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m encoder_outputs \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1599\u001b[0m     encoder_outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1600\u001b[0m \u001b[43m        \u001b[49m\u001b[43minput_ids\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minput_ids\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1601\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1602\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhead_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhead_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1603\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs_embeds\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minputs_embeds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1604\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_attentions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_attentions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1605\u001b[0m \u001b[43m        \u001b[49m\u001b[43moutput_hidden_states\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_hidden_states\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1606\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreturn_dict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreturn_dict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1607\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1608\u001b[0m \u001b[38;5;66;03m# If the user passed a tuple for encoder_outputs, we wrap it in a BaseModelOutput when return_dict=True\u001b[39;00m\n\u001b[1;32m   1609\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m return_dict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(encoder_outputs, BaseModelOutput):\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/transformers/models/bart/modeling_bart.py:1152\u001b[0m, in \u001b[0;36mBartEncoder.forward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m   1149\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou have to specify either input_ids or inputs_embeds\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 1152\u001b[0m     inputs_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_tokens\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_ids\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_scale\u001b[49m\n\u001b[1;32m   1154\u001b[0m embed_pos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_positions(\u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m   1155\u001b[0m embed_pos \u001b[38;5;241m=\u001b[39m embed_pos\u001b[38;5;241m.\u001b[39mto(inputs_embeds\u001b[38;5;241m.\u001b[39mdevice)\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 64.00 MiB. GPU 0 has a total capacity of 3.94 GiB of which 38.75 MiB is free. Process 5468 has 1.39 GiB memory in use. Including non-PyTorch memory, this process has 2.11 GiB memory in use. Of the allocated memory 2.00 GiB is allocated by PyTorch, and 52.88 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "labels = framing_labels(articles)\n",
    "\n",
    "labels_df = pd.DataFrame(labels)\n",
    "_, ax = framing_labels.visualize(labels_df.mean().to_dict(), xerr=labels_df.sem())\n",
    "ax.xaxis.set_major_formatter(mticker.ScalarFormatter())\n",
    "plt.xticks([0.1, 0.5, 1])\n",
    "plt.title(\"Example Frame Lables\")\n",
    "plt.axvline(0.5, color=\"red\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dimensions = framing_dimensions(texts)\n",
    "test_dimens_df = pd.DataFrame(dimensions)\n",
    "g = framing_dimensions.visualize(test_dimens_df)\n",
    "g.axes[0].set_axisbelow(True)\n",
    "g.axes[0].yaxis.grid(color='gray', linestyle='dashed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| hide\n",
    "import nbdev; nbdev.nbdev_export()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
