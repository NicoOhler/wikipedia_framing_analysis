USA Today (web site) 
Thursday, April 20, 2017 - 15:34 UTC -0400
The truth about why people don't trust science
Alia E. Dastagir, USA TODAY
Americans aren’t at war with science — just with themselves.

People protest for greater action against climate change during the People's Climate March on September 21, 2014 in New York City.

Climate change activists carry signs as they march during a protest in Philadelphia a day before the start of the Democratic National Convention, on July 24, 2016.

Scientists and their allies are expected to fill the streets of the nation’s capital Saturday for Earth Day's March for Science, advocating for the importance of scientific truth in an era we’ve ominously been told doesn’t value the truth any longer.

Advocates say science is under attack. President Trump’s Environmental Protection Agency chief Scott Pruitt doesn’t accept evidence that shows humans are causing climate change. Education Secretary Betsy DeVos' 2001 comments on wanting to “advance God’s kingdom” through education have educators worried she could undermine the teaching of evolution in public schools. Trump’s budget blueprint slashes funding for the National Institutes of Health and the Department of Energy's Office of Science.

Esteemed astrophysicist Neil deGrasse Tyson, in an impassioned video on his Facebook page, said he fears people have lost the ability to judge what's true and what's not.

"That is a recipe for the complete dismantling of our informed democracy," he says.

The scientific community is alarmed by the Trump administration, and by what they see as the diminishing role of objective science in American life. But the General Social Survey, one of the oldest and most comprehensive recurring surveys of American attitudes, shows that although trust in public institutions has declined over the last half century, science is the one institution that has not suffered any erosion of public confidence. Americans who say they have a great deal of confidence in science has hovered around 40% since 1973.

Many scientists say there is no war on their profession at all.

According to the 2016 GSS data released this month, people trust scientists more than Congress (6%) and the executive branch (12%). They trust them more than the press (8%). They have more trust in scientists than in the people who run major companies (18%), more than in banks and financial institutions (14%), the Supreme Court (26%) or organized religion (20%).

So why all the headlines about the "war on science"?

Though science still holds an esteemed place in America, there is a gap between what scientists and some citizens think — a rift that is not entirely new — on issues such as climate change, nuclear power, genetically modified foods, human evolution and childhood vaccines.

Americans don’t reject science as a whole. People love the weather forecast. They love their smartphones. When people reject science, it’s because they’re asked to believe something that conflicts with a deeply held view, whether political (my party does not endorse that), religious (my god did not say that) or personal (that's not how I was raised).

Many conservatives reject the science of man-made climate change, just as many liberals reject the science that shows nuclear energy can safely combat it. The views we express signal which political group we belong to. The gap between what science shows and what people believe, experts say, is about our identity.

“The issue of climate change isn’t about what you know,” said Dan Kahan, a professor of psychology and law at Yale and a member of the university’s Cultural Cognition Project. “It’s about who you are.”

Polarization has exacerbated our differences, and we know some of what’s to blame: The rise of social media. A more partisan press. A dearth of universally-accepted experts. And greater access to information, which Christopher Graves, president and founder of the Ogilvy Center for Behavioral Science, said does not tug us toward the center, but rather makes us more polarized.

“A human being cannot grasp something as a fact if it in any way undermines their identity,” Graves said. “And that is an immutable human foible. These things have always been there, but not at scale."

The GSS data show confidence in institutions overall has been in decline since the 1970s, though political scientists are quick to caution that this is an imperfect benchmark.

Brendan Nyhan, a political scientist at Dartmouth College, said trust in the mid-20th century was unnaturally high and polarization was unnaturally low, bolstered by unusual growth in middle class income and a reduction of inequality, which is when the "20th century version of the American dream and the trust in government to produce it was fully mythologized."

“There was an usually high level of trust that came out of World War II, before the turn towards a more cynical view of the institutions of society — especially politics and media — after Vietnam and Watergate," Nyhan said.

So how much more polarization can we expect?

Social scientists aren't sure, but they agree Trump complicates things.

"He really is an us-versus-them figure," Kahan said. "People aren’t thinking about the arguments. They’re thinking about what side they're on."

Think about the way you search for information. If you’re a new mom who believes vaccines cause autism (and a number of women in your mommy group do, too) are you searching for research that shows whether they actually do, or are you Googling “vaccines cause autism” to find stories to affirm your belief? (Studies show there is no link between vaccines and autism.)

The mother above is probably motivated by fear. Such “motivated reasoning,” says political scientist Charles Taber of Stony Brook University, shows that we are all fundamentally biased.

“You have a basic psychological tendency to perpetuate your own beliefs,” he said “to really … discount anything that runs against your own prior views.”

It gets even more complicated. Once we’ve convinced ourselves of something, research suggests facts don’t appeal to us. A study co-led by Nyhan found that trying to correct a person’s misperception can have a “backfire effect.” When you encounter facts that don’t support your idea, your belief in that idea actually grows stronger.

So what if we did a better job teaching people how science works? Doesn't help, Kahan said. Research shows people with the most science intelligence are also the most partisan.

It’s not knowledge but curiosity, Kahan says, that makes us more likely to accept scientific truths. A recent study that Kahan led found people with more scientific curiosity were more likely to be open-minded about information that challenged their existing political views.

And arguing helps, too. Scientists Hugo Mercier and Dan Sperber contend in their new book, The Enigma of Reason, that reason isn't something that evolved so humans could solve problems on their own. It developed so we could work together.

Instead of forcing someone to agree that climate change is caused by humans, Graves said, you can stop once you agree that, for example, flooding in Florida is a problem, and that you have to fix it (the bipartisan Southeast Florida Regional Climate Change Compact can teach us about that).

Marcia McNutt, an American geophysicist and president of the National Academy of Sciences, said she isn’t worried about a crisis of science, though she hopes the march will drive home that “science is about the unbiased search for truth" — and that benefits everyone.

“Being a scientist only means that when I have an intuition about something, I test that intuition, and see if I’m right,” she said. “A very, very smart mentor told me once, ‘I don't trust anyone who hasn't at least changed their mind once in their career.’”

Science, it appears, may have more lessons for us than we think.