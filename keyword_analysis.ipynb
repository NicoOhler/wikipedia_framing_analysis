{"cells":[{"cell_type":"code","execution_count":1,"metadata":{},"outputs":[{"data":{"text/plain":["'\\npip install scattertext\\npip install astropy\\npip install empath\\npip install flashtext\\npip install gensim\\npip install umap-learn\\npip install -U pip setuptools wheel\\npip install -U spacy\\npython3 -m spacy download en_core_web_sm\\n'"]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["\"\"\"\n","pip install scattertext\n","pip install astropy\n","pip install empath\n","pip install flashtext\n","pip install gensim\n","pip install umap-learn\n","pip install -U\n","pip setuptools wheel\n","pip install -U spacy\n","python3 -m spacy download en_core_web_sm\n","\"\"\""]},{"cell_type":"code","execution_count":2,"metadata":{},"outputs":[],"source":["import scattertext as st\n","import spacy\n","import nltk\n","import os\n","import pandas as pd\n","\n","nlp = spacy.load(\"en_core_web_sm\")"]},{"cell_type":"code","execution_count":3,"metadata":{},"outputs":[],"source":["def get_articles_by_directory(directory):\n","    articles = []\n","    article_paths = []\n","    for root, dirs, files in os.walk(directory):\n","        for file in files:\n","            if file.endswith(\".txt\"):\n","                try:\n","                    with open(os.path.join(root, file), \"r\", errors=\"ignore\") as f:\n","                        articles.append(f.read())\n","                        article_paths.append(os.path.join(root, file))\n","                except Exception as e:\n","                    print(f\"Error reading file: {os.path.join(root, file)}\\n{e}\")\n","                    continue\n","    print(f\"Found {len(articles)} articles in {directory}.\")\n","    return articles, article_paths\n","\n","def tokenize(articles):\n","    tokenized_articles = []\n","    for article in articles:\n","        try:\n","            tokenized_articles.append(nltk.sent_tokenize(article))\n","        except Exception as e:\n","            print(f\"Tokenization error:\\n{e}\")\n","            continue\n","    print(f\"Tokenized {len(articles)} articles.\")\n","    return tokenized_articles\n","\n","def get_type(path):\n","    if \"Presse\" in path:\n","        return \"Presse\"\n","    elif \"NGO\" in path:\n","        return \"NGO\"\n","    elif \"IGO\" in path:\n","        return \"IGO\"\n","    assert False, f\"Could not determine type of article: {path}\"\n","\n","def get_org(path):\n","    path = path.split(\"/\")[-1] # remove everything before the last slash\n","    path = path.split(\"-\")[0] # remove everything after the first hyphen\n","    return path\n","\n"]},{"cell_type":"code","execution_count":4,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["Found 1561 articles in COP/articles/by_org/.\n","Tokenized 1561 articles.\n","                                             article  \\\n","0  A report of Working Group I of the Intergovern...   \n","1  Climate Change 2007: Synthesis Report Summary ...   \n","2  Contribution of Working Group II to the Fourth...   \n","3  Contribution of Working Group III to the Fourt...   \n","4   Investing in REDD-plus Consensus Recommendati...   \n","\n","                                                path type   org  \n","0  COP/articles/by_org/IGO/IGO_COP15/IPCC-2007-1.txt  IGO  IPCC  \n","1  COP/articles/by_org/IGO/IGO_COP15/IPCC-2007-2.txt  IGO  IPCC  \n","2  COP/articles/by_org/IGO/IGO_COP15/IPCC-2007-3.txt  IGO  IPCC  \n","3  COP/articles/by_org/IGO/IGO_COP15/IPCC-2007-4.txt  IGO  IPCC  \n","4  COP/articles/by_org/IGO/IGO_COP15/REDD-2010-3.txt  IGO  REDD  \n"]}],"source":["articles, article_paths = get_articles_by_directory(\"COP/articles/by_org/\")\n","articles = tokenize(articles)\n","articles = [\" \".join(article) for article in articles]\n","\n","types = [get_type(path) for path in article_paths]\n","orgs = [get_org(path) for path in article_paths]\n","articles_df = pd.DataFrame({\"article\": articles, \"path\": article_paths, \"type\": types, \"org\": orgs})\n","print(articles_df.head())"]},{"cell_type":"code","execution_count":6,"metadata":{},"outputs":[],"source":["corpus = st.CorpusFromPandas(\n","    articles_df,\n","    category_col=\"type\",\n","    text_col=\"article\",\n","    nlp=nlp\n",").build()\n"]},{"cell_type":"code","execution_count":7,"metadata":{},"outputs":[{"name":"stdout","output_type":"stream","text":["['climate', 'emissions', 'warming', 'fossil', 'adaptation', 'renewable', 'carbon', 'ghg', 'mitigation', 'obama']\n"]}],"source":["print(list(corpus.get_scaled_f_scores_vs_background().index[:10]))"]},{"cell_type":"code","execution_count":8,"metadata":{},"outputs":[{"ename":"","evalue":"","output_type":"error","traceback":["\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n","\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n","\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n","\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."]}],"source":["dispersion = st.Dispersion(corpus)\n","dispersion_df = dispersion.get_df()\n","\"\"\"\n","dispersion_df = dispersion_df.assign(\n","    X=lambda df: df.Frequency,\n","    Xpos=lambda df: st.Scalers.log_scale(df.X),\n","    Y=lambda df: df[\"Rosengren's S\"],\n","    Ypos=lambda df: st.Scalers.scale(df.Y),\n",")\n","\"\"\"\n","dispersion_df['X'] = dispersion_df['Frequency']\n","dispersion_df['Xpos'] = st.Scalers.log_scale(dispersion_df['X'])\n","dispersion_df['Y'] = dispersion_df[\"Rosengren's S\"]\n","dispersion_df['Ypos'] = st.Scalers.scale(dispersion_df['Y'])\n","dispersion_df.head(3)"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["html = st.dataframe_scattertext(\n","    corpus,\n","    plot_df=dispersion_df,\n","    metadata=corpus.get_df()[\"org\"]\n","    + \" (\"\n","    + corpus.get_df()[\"type\"].str.upper()\n","    + \")\",\n","    ignore_categories=True,\n","    x_label=\"Log Frequency\",\n","    y_label=\"Rosengren's S\",\n","    y_axis_labels=[\"Less Dispersion\", \"Medium\", \"More Dispersion\"],\n","    #term_description_column=[\"Frequency\"]\n",")\n","with open(\"Test.html\", \"w\") as f:\n","    f.write(html.encode(\"utf-8\"))\n"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["# todo filter out stopwords\n","# ? factor out correlation\n","from sklearn.neighbors import KNeighborsRegressor\n","\n","dispersion_df = dispersion_df.assign(\n","    Expected=lambda df: KNeighborsRegressor(n_neighbors=10).fit(\n","        df.X.values.reshape(-1, 1), df.Y\n","    ).predict(df.X.values.reshape(-1, 1)),\n","    Residual=lambda df: df.Y - df.Expected,\n","    ColorScore=lambda df: st.Scalers.scale_center_zero_abs(df.Residual)\n",")   \n","\n","html = st.dataframe_scattertext(\n","    corpus,\n","    plot_df=dispersion_df,\n","    metadata=corpus.get_df()['org'] + ' (' + corpus.get_df()['type'].str.upper() + ')',\n","    ignore_categories=True,\n","    x_label='Log Frequency',\n","    y_label=\"Rosengren's S\",\n","    y_axis_labels=['Less Dispersion', 'Medium', 'More Dispersion'],\n","    color_score_column='ColorScore',\n","    header_names={'upper': 'Lower than Expected', 'lower': 'More than Expected'},\n","    left_list_column='Residual',\n","    background_color='#e5e5e3'\n",")\n","with open(\"Test2.html\", \"w\") as f:\n","    f.write(html.encode(\"utf-8\"))"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"}},"nbformat":4,"nbformat_minor":2}
